Availability: Public
Title:Audio System Overview
Crumbs: %ROOT%, Engine, Engine/Audio
Description:Overview of the audio system used for playing in-game sounds, including the use of SoundCues node-based audio assets.
version: 4.12
parent:Engine/Audio
type:overview
order:1

[VAR:Topic]
[OBJECT:Topic]
	[PARAM:image]
		![%Engine/Audio/Overview:title%](Engine/Audio/audio_topic.png)
	[/PARAM]
	[PARAM:icon]
		![](%ROOT%/audio_icon.png)(convert:false)
	[/PARAM]
	[PARAM:title]
		%Engine/Audio/Overview:title%
	[/PARAM]
	[PARAM:description]
		%Engine/Audio/Overview:description%
	[/PARAM]
	[PARAM:path]
		[RELATIVE:Engine/Audio/Overview]
	[/PARAM]
[/OBJECT]
[/VAR]
[VAR:TopicCompact]
[OBJECT:TopicCompact]
	[PARAM:image]
		![%Engine/Audio/Overview:title%](Engine/Audio/audio_topic.png)
	[/PARAM]
	[PARAM:icon]
		![](%ROOT%/audio_icon.png)(convert:false)
	[/PARAM]
	[PARAM:title]
		%Engine/Audio/Overview:title%
	[/PARAM]
	[PARAM:description]
		%Engine/Audio/Overview:description%
	[/PARAM]
	[PARAM:path]
		[RELATIVE:Engine/Audio/Overview]
	[/PARAM]
[/OBJECT]
[/VAR]

[TOC(start:2)]


The audio system in Unreal Engine 4 is made up of several components, each working together to produce the audio experience for players. 
When you import an audio file into the engine and drop it in a level, you will have several options such as the basic **Volume** or **Pitch** levels to adjust, as well as more fine-tuning settings such as **Sound Attenuation**, which defines how a sound is heard based on your distance from its origin. 

Unreal Engine 4 also allows for building composite sounds in the form of **Sound Cues** and the **Sound Cue Editor** which enable you to combine sounds as well as apply modifiers called **Sound Nodes** to alter the final output. 
There are additional elements that are used to define how a sound is heard or played which are covered on this page and links to more documentation can be found in their respective sections. 


## Importing Sound Files

Unreal Engine 4 currently supports importing uncompressed little endian 16 bit wave files at any sample rate (see the chart below). For best results, it is recommended that sample rates of 44100 Hz or 22050 Hz be used. 

| --- | --- |
| Specifications| PCM, ADPCM, DVI ADPCM |
| Format | .WAV |
| Bit Rate | 16 |
| Speaker Channels | Mono, Stereo, 2.1, 4.1, 5.1 6.1, 7.1 |

Importing a sound file into the editor generates a **Sound Wave** asset that can be dropped directly into a level or can be used to create a Sound Cue and edited inside the **Sound Cue Editor**. 

Importing a sound file can be handled in two ways: 

In the **Content Browser**:

1.	 From the Content Browser, click the **Import** button (pictured below).
	![](ImportButton_UI.png)
1. Select the .WAV file you wish to import.

Or

1. Select your sound file in a Windows File Explorer window.
1. Click and drag it into the **Content Browser** inside Unreal Engine 4.

Unreal Engine 4 also supports multichannel (e.g. 5.1) sounds and uses a special naming convention when importing your files for multichannel use.

For more information on importing and multichannel usage, refer to the [Audio Files](Engine/Audio/WAV/) documentation. 


## Sound Asset Types

To add a Sound asset, click the ![](CB_button_NewAsset.png) button from the **Content Browser** and select **Sounds** followed by the asset you wish to add from the menu. 

![](selectSoundAsset.png)(h:400)

There are several different types of Sound assets that can be added to your projects which are described below. 

### Sound Cue
![](soundCueEditor.png)(w:640)

Sound Cues are composite sounds that allow you to modify the behavior of audio playback, combine audio effects, and apply audio modifiers with **Sound Nodes** to alter the final output. 

For more information, refer to the [Sound Cue Editor](Engine/Audio/SoundCues/Editor) page. 

### Sound Attenuation
Sound Attenuation assets allow the definition of attenuation properties in a reusable manner. Any place you can specify one-time use attenuation properties, you can instead specify the Sound Attenuation asset. This allows adjustment to attenuation properties without having to revisit every sound individually.

![](soundAttenuation.png)

For more information on **Attenuation**, see the [Sound Attenuation](Engine/Audio/DistanceModelAttenuation) page.


### Reverb Effects

**Reverb Effects** are a definable asset with several properties that can be easily adjusted and applied to any **Audio Volume** placed in your level. 
With a Reverb Effect, you can adjust settings (pictured below) that will allow you to control elements like the echo density, overall reverb gain, air absorption, and more to help craft the overall feel you may be after.  

![](reverbeffect.png)


### Sound Class
**Sound Classes** are a collection of properties that can be applied to a number of Sound assets.

The properties inside a Sound Class act as multipliers to the existing values and will be carried out by all Sound assets assigned to the Sound Class.  

![](soundClassProperties.png)

Hierarchies can be created by adding **Child Classes**, which will allow you to pass down only specified properties from the parent class to children classes. You can connect class together inside the **Sound Class Editor**, which shares a similar node-based interface as seen in the **Sound Cue Editor**.

 ![](soundClassEditor.png)(w:640)

You can also add **Passive Sound Mixes** (see the **Sound Mix** section below) to a Sound Class which will kick in and activate automatically whenever the Sound Class is played (for example, having music automatically lower whenever a dialogue Sound Class is played).  


### Sound Mix
Sound Mixes allow you to set the **EQ Settings** (Equalizer Settings) and modify **Volume** and **Pitch** properties of Sound Classes.

![](soundMixDetails.png)

Multiple Sound Mixes can be active at the same time, all contributing to the overall audio effect. You can **Push** (Activate) or **Pop** (Deactivate) Sound Mixes directly inside a Blueprint with the **Push Sound Mix Modifier** and **Pop Sound Mix Modifier** nodes or activate them passively whenever a sound with a given Sound Class is playing within a specified threshold.

However, the **Push/Pop** method can become very complex quickly if you have a large number of mixes you are trying to switch between. This is where the **Set Sound Mix Class Override** Blueprint Node comes into play. It can set an active Sound Mix to use any Sound Class you have, and interpolate between its current Sound Class and the new Sound Class over time.

![](image_37.jpg)

Then you can set the Sound Mix back to its original setting by using the **Clear Sound Mix Class Override**.

Within the Sound Mix asset itself, which can be opened by **Double-Clicking** the asset in the **Content Browser**, several properties exist. 
You can specify EQ Settings for the mix to adjust the high, middle, and low frequencies and gains. As the EQ Settings of multiple Sound Mixes cannot be combined, the **EQ Priority** allows you to control which active mix's properties are applied at any given time.

Inside the Sound Classes section, you set which Sound Classes are to be affected by the mix.  For each Sound Class you can set the **Volume** or **Pitch** adjusters, set if the mix settings are to be applied to Child Classes, or modify the **VoiceCenterChannelVolume**.

The Sound Mix section allows you to specify how the Sound Mix properties are applied or removed.  **Delay** indicates how long before the mix properties should begin being applied.  **Fade in Time** and **Fade out Time** specify how quickly to transition from no effect to the specified properties.  **Duration** allows a pushed Sound Mix to automatically pop itself after the specified duration.  A value of -1 indicates to never automatically pop and passively applied Sound Mixes will not automatically pop.


### Dialogue Voice and Dialogue Wave
The **Dialogue Voice** and **Dialogue Wave** assets are used for generating in-game dialogue events, crafting subtitles, and for supplementing localization efforts. 

When editing a newly created Dialogue Voice asset, you can define the **Gender** and **Plurality** of a voice actor and although you do not specify any audio assets inside the Dialogue Voice, the information provided here can be referenced inside the Dialogue Wave. 

The Dialogue Wave provides more options and is where the connection between audio and speaker/listener(s) is made. It is also where the correlation between dialogue audio and subtitle text is made. The Dialogue Wave represents a single line of dialogue and the core component of the Dialogue Wave settings is the **Dialogue Contexts** section. 

![](dialogueWaveDetails.png)

Inside the **Dialogue Contexts** section, you can specify the **Speaker** or who the dialogue is being **Directed At** in their respective sections by assigning a Dialogue Voice. 
The actual audio line of dialogue can be added as a Sound Wave by expanding the context window and choosing the desired asset from the drop-down menu or by pointing to an asset in the **Content Browser**. 

In the event that you have multiple actors who say the same line of dialogue, the **Add Dialogue Context** option will allow you to create a new entry for the dialogue where you can set new **Speaker** and **Directed At** sections.

[REGION:note]
Dialogue Wave assets can also be applied to a Sound Cue by using the Dialogue Player node inside the **Sound Cue Editor**. Also, you can access a Dialogue Wave directly from within a Blueprint using the **Play Dialogue at Location** and **Play Dialogue Attached** nodes. 
[/REGION]

In addition to Dialogue Contexts, you can apply a **Mature** filter which flags the dialogue as containing mature/adult content. Under **Script**, you can enter the text that is spoken in the attached audio inside the **Spoken Text** section. 
You can also enter contextual information for the audio for translation purposes or for notes to a voice actor in the **Voice Actor Direction** section. 

For more information, see the [](Engine/Audio/Dialogue) example.


## Strategies

### General Volume Guidelines

Regarding loudest potential volume, there is variation in the overall bandwidth to work within. 
For example, a stereo file at 1.0 volume will be 2x louder than a mono file, likewise (4) mono files would be 4x louder. However, eventually you will hit the overall threshold and the output will begin to clip and distort.

On any given Sound Cue, volume settings up to around 2.0 will increase the perceived loudness of the audio file, and anything above that would not. 
A single cue will never distort, but you would not want all of your files at maximum volume because it will likely overload when multiple cues play simultaneously in-game.

You may want to consider coming up with a consistent volume scheme, or at least some general guidelines for your volumes:

|Category | Approximate Volume | 
| --- | --- |
| Dialog | 1.4 | 
| Music | 0.75 | 
| Weapons | 1.1 | 
| Ambience | 0.5 | 

Additionally, you may consider using mono assets almost everywhere to maintain consistency, with the exception of music.

### Volume Ducking

**Volume Ducking** is generally used to decrease volumes of all other sounds besides the one that needs to be heard, most commonly dialog. 

The process usually consists of: 

* Identifying a Sound Class that should cause ducking (e.g. dialog).
* When a sound from that Sound Class is triggered, other Sound Classes begin to decrease in volume (Sound Mix : Fade in Time = 0.3 seconds).
* Specify the amount other Sound Classes decrease in volume (Sound Mix : Volume Adjuster = 0.4).
* When a sound from a ducking Sound Class stops, other classes increase in volume back to normal volume (Sound Mix : Fade Out Time = 0.3 seconds).
* You may also want Sound Class exceptions to the ducking process (e.g. music), or a Sound Class called Exceptions that is not affected.

Using a similar approach will ensure that emphasis is placed on the important aspects of your audio and that it is not "drowned" out by superficial or un-important audio elements. 


### Optimizing Sound Memory Usage

When authoring content, it is best to use the lowest sample rate that maintains audio fidelity. For example, dialog generally still sounds good at 22.1kHz, whereas commonly played effects with high frequencies (such as gunshots) need to be higher (e.g. 40.0kHz). 
A similar heuristic can be applied to the quality setting.




